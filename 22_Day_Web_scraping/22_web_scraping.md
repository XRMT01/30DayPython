<div align="center">
  <h1> 30 Days Of Python: Day 22 - Web Scraping </h1>
  <a class="header-badge" target="_blank" href="https://www.linkedin.com/in/asabeneh/">
  <img src="https://img.shields.io/badge/style--5eba00.svg?label=LinkedIn&logo=linkedin&style=social">
  </a>
  <a class="header-badge" target="_blank" href="https://twitter.com/Asabeneh">
  <img alt="Twitter Follow" src="https://img.shields.io/twitter/follow/asabeneh?style=social">
  </a>

<sub>Author:
<a href="https://www.linkedin.com/in/asabeneh/" target="_blank">Asabeneh Yetayeh</a><br>
<small> Second Edition: July, 2021</small>
</sub>
</div>

[<< Day 21](../21_Day_Classes_and_objects/21_classes_and_objects.md) | [Day 23 >>](../23_Day_Virtual_environment/23_virtual_environment.md)

![30DaysOfPython](../images/30DaysOfPython_banner3@2x.png)

- [ğŸ“˜ Day 22](#-day-22)
  - [Python Web Scraping](#python-web-scraping)
    - [What is Web Scrapping](#what-is-web-scrapping)
  - [ğŸ’» Exercises: Day 22](#-exercises-day-22)

# ğŸ“˜ ç¬¬äºŒåäºŒå¤©

##Python WebæŠ“å–

###ä»€ä¹ˆæ˜¯ç½‘ç»œå‰ªè´´

äº’è”ç½‘ä¸Šå……æ»¡äº†å¯ç”¨äºä¸åŒç›®çš„çš„å¤§é‡æ•°æ®ã€‚ä¸ºäº†æ”¶é›†è¿™äº›æ•°æ®ï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“å¦‚ä½•ä»ç½‘ç«™ä¸ŠæŠ“å–æ•°æ®ã€‚

ç½‘ç»œæŠ“å–æ˜¯ä»ç½‘ç«™ä¸­æå–å’Œæ”¶é›†æ•°æ®å¹¶å°†å…¶å­˜å‚¨åœ¨æœ¬åœ°è®¡ç®—æœºæˆ–æ•°æ®åº“ä¸­çš„è¿‡ç¨‹ã€‚

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨beautifulsoupå’ŒrequestsåŒ…æ¥æŠ“å–æ•°æ®ã€‚æˆ‘ä»¬ä½¿ç”¨çš„åŒ…ç‰ˆæœ¬æ˜¯beautifulsoup 4ã€‚

è¦å¼€å§‹æŠ“å–ç½‘ç«™ï¼Œæ‚¨éœ€è¦_requests_ã€_beautifoulSoup4_å’Œ_website_ã€‚

```sh
pip install requests
pip install beautifulsoup4
```

è¦ä»ç½‘ç«™ä¸ŠæŠ“å–æ•°æ®ï¼Œéœ€è¦å¯¹HTMLæ ‡ç­¾å’ŒCSSé€‰æ‹©å™¨æœ‰åŸºæœ¬çš„äº†è§£ã€‚æˆ‘ä»¬ä½¿ç”¨HTMLæ ‡ç­¾ã€ç±»æˆ–/å’Œidå®šä½ç½‘ç«™å†…å®¹ã€‚
è®©æˆ‘ä»¬å¯¼å…¥è¯·æ±‚å’ŒBeautifulSoupæ¨¡å—

```py
import requests
from bs4 import BeautifulSoup
```

è®©æˆ‘ä»¬ä¸ºè¦æŠ“å–çš„ç½‘ç«™å£°æ˜urlå˜é‡ã€‚

```py

import requests
from bs4 import BeautifulSoup
url = 'https://archive.ics.uci.edu/ml/datasets.php'

# Lets use the requests get method to fetch the data from url

response = requests.get(url)
# lets check the status
status = response.status_code
print(status) # 200 means the fetching was successful
```

```sh
200
```

ä½¿ç”¨beautifulSoupè§£æé¡µé¢å†…å®¹

```py
import requests
from bs4 import BeautifulSoup
url = 'https://archive.ics.uci.edu/ml/datasets.php'

response = requests.get(url)
content = response.content # we get all the content from the website
soup = BeautifulSoup(content, 'html.parser') # beautiful soup will give a chance to parse
print(soup.title) # <title>UCI Machine Learning Repository: Data Sets</title>
print(soup.title.get_text()) # UCI Machine Learning Repository: Data Sets
print(soup.body) # gives the whole page on the website
print(response.status_code)

tables = soup.find_all('table', {'cellpadding':'3'})
# We are targeting the table with cellpadding attribute with the value of 3
# We can select using id, class or HTML tag , for more information check the beautifulsoup doc
table = tables[0] # the result is a list, we are taking out data from it
for td in table.find('tr').find_all('td'):
    print(td.text)
```

å¦‚æœè¿è¡Œæ­¤ä»£ç ï¼Œæ‚¨å¯ä»¥çœ‹åˆ°æå–å·²å®Œæˆä¸€åŠã€‚ä½ å¯ä»¥ç»§ç»­åšï¼Œå› ä¸ºè¿™æ˜¯ç»ƒä¹ 1çš„ä¸€éƒ¨åˆ†ã€‚
å¦‚éœ€å‚è€ƒï¼Œè¯·æŸ¥é˜…[beautifulsoupæ–‡æ¡£](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#quick-å¼€å§‹ï¼‰

ğŸŒ• ä½ å¾ˆç‰¹åˆ«ï¼Œä½ æ¯å¤©éƒ½åœ¨è¿›æ­¥ã€‚ä½ åªæœ‰å…«å¤©çš„æ—¶é—´èµ°å‘ä¼Ÿå¤§ã€‚ç°åœ¨åšä¸€äº›é”»ç‚¼ä½ çš„å¤§è„‘å’Œè‚Œè‚‰ã€‚

## ğŸ’» ç»ƒä¹ ï¼šç¬¬22å¤©

1. æŠ“å–ä»¥ä¸‹ç½‘ç«™å¹¶å°†æ•°æ®å­˜å‚¨ä¸ºjsonæ–‡ä»¶ï¼ˆurl='http://www.bu.edu/president/boston-university-facts-stats/').
2. æå–æ­¤urlä¸­çš„è¡¨(https://archive.ics.uci.edu/ml/datasets.php)å¹¶å°†å…¶æ›´æ”¹ä¸ºjsonæ–‡ä»¶
3. åºŸå¼ƒpresidentsè¡¨ï¼Œå°†æ•°æ®å­˜å‚¨ä¸ºjsonæ ¼å¼(https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States). è¡¨æ ¼ç»“æ„ä¸å¤ªåˆç†ï¼ŒæŠ¥åºŸå¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´time.

ğŸ‰ CONGRATULATIONS ! ğŸ‰

[<< Day 21](../21_Day_Web_scraping/21_class_and_object.md) | [Day 23 >>](../23_Day_Virtual_environment/23_virtual_environment.md)
